{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment and Generate a Dataset Based on the 10 Objects\n",
    "\n",
    "Use the 10 object types as the basis for creating a local dataset for fine-tuning the model\n",
    "The data generated from this file was uploaded to Roboflow to create the final dataset used for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with augmented images created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "\n",
    "# Define the classes for the objects\n",
    "classes = [\n",
    "    'cell phone', 'remote', 'knife', 'book', 'spoon',\n",
    "    'cup', 'scissors', 'fork', 'toothbrush', 'ball'\n",
    "]\n",
    "\n",
    "# Paths for the dataset\n",
    "images_dir = \"../Objects/\"\n",
    "output_dir = \"local_dataset/\"\n",
    "\n",
    "# Create dataset structure\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    os.makedirs(f\"{output_dir}/images/{subset}\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_dir}/labels/{subset}\", exist_ok=True)\n",
    "\n",
    "# Data augmentation pipeline using Albumentations\n",
    "augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=25, p=0.5),\n",
    "    A.RandomScale(scale_limit=0.2, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5)\n",
    "])\n",
    "\n",
    "# Dataset split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "def get_class_id(image_path):\n",
    "    \"\"\"\n",
    "    Get the class ID for an image based on its file path.\n",
    "    Classify the 10 objects into their correct class.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        int: The class ID corresponding to the image.\n",
    "    \"\"\"\n",
    "    class_ids = {\n",
    "        \"../Objects/O1.jpg\": 1,\n",
    "        \"../Objects/O2.jpg\": 2,\n",
    "        \"../Objects/O3.jpg\": 3,\n",
    "        \"../Objects/O4.jpg\": 4,\n",
    "        \"../Objects/O5.jpg\": 5,\n",
    "        \"../Objects/O6.jpg\": 6,\n",
    "        \"../Objects/O7.jpg\": 7,\n",
    "        \"../Objects/O8.jpg\": 8,\n",
    "        \"../Objects/O9.jpg\": 9,\n",
    "        \"../Objects/O10.jpg\": 10\n",
    "    }\n",
    "\n",
    "    return class_ids.get(image_path)\n",
    "\n",
    "def augment_and_save(image_path, class_id, output_dir, subset, num_augmentations=10):\n",
    "    \"\"\"\n",
    "    Augment and save images with their labels.\n",
    "\n",
    "    Args:\n",
    "        image_path (Path): Path to the input image.\n",
    "        class_id (int): Class ID of the image.\n",
    "        output_dir (str): Base directory to save the augmented images and labels.\n",
    "        subset (str): Subset (train, val, or test) to which the image belongs.\n",
    "        num_augmentations (int): Number of augmented images to generate. Default is 10.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to read image at {image_path}\")\n",
    "\n",
    "    bbox = [0.2, 0.2, 0.8, 0.8]  # Bounding box with normalized x_center, y_center, width, height\n",
    "    annotations = f\"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\"\n",
    "\n",
    "    for i in range(num_augmentations):\n",
    "        # Apply the augmentations\n",
    "        augmented = augmentations(image=image)\n",
    "        augmented_image = augmented[\"image\"]\n",
    "        augmented_image_name = f\"{image_path.stem}_{subset}_{i}.jpg\"\n",
    "        cv2.imwrite(f\"{output_dir}/images/{subset}/{augmented_image_name}\", augmented_image)\n",
    "\n",
    "        # Save corresponding label\n",
    "        label_path = f\"{output_dir}/labels/{subset}/{augmented_image_name.replace('.jpg', '.txt')}\"\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(annotations)\n",
    "\n",
    "# Load and shuffle all images (to avoid all of a certain image being categorized in one set)\n",
    "all_images = list(Path(images_dir).glob(\"*.jpg\"))\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Split images into train, val, and test subsets\n",
    "num_images = len(all_images)\n",
    "train_images = all_images[:int(num_images * train_ratio)]\n",
    "val_images = all_images[\n",
    "    int(num_images * train_ratio):int(num_images * (train_ratio + val_ratio))\n",
    "]\n",
    "test_images = all_images[int(num_images * (train_ratio + val_ratio)):]\n",
    "\n",
    "# Augment and save images for each subset\n",
    "dataset_combined = zip(\n",
    "    ['train', 'val', 'test'], \n",
    "    [train_images, val_images, test_images]\n",
    ")\n",
    "\n",
    "for subset, subset_images in dataset_combined:\n",
    "    for image_path in subset_images:\n",
    "        class_id = get_class_id(str(image_path))\n",
    "        if class_id is None:\n",
    "            print(f\"Skipping unrecognized image: {image_path}\")\n",
    "            continue\n",
    "        augment_and_save(image_path, class_id, output_dir, subset)\n",
    "\n",
    "# Create data.yaml for exporting to Roboflow \n",
    "# which will ultimately be used to train a YOLO model\n",
    "yaml_content = f\"\"\"\n",
    "path: {output_dir}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "\"\"\"\n",
    "for i, cls in enumerate(classes):\n",
    "    yaml_content += f\"  {i}: {cls}\\n\"\n",
    "\n",
    "with open(f\"{output_dir}/data.yaml\", 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"Dataset with augmented images created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
